name: Scrape Website

on:
  schedule:
    - cron: '0 0 * * *' # This cron job runs daily at midnight UTC
  workflow_dispatch: # Allows manual triggering of the workflow

permissions:
  contents: write  # Grant write permissions to the repository contents
  issues: write    # Grant write permissions to create issues

jobs:
  scrape_job:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'  # Use the version of Python you need

    - name: Install Python Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4

    - name: Install Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'  # Use the version of Node.js you need

    - name: Install Puppeteer
      run: npm install puppeteer

    - name: Run scraper
      run: python scraper.py

    - name: Run Feed Fetcher
      run: python atom_feed_fetcher.py

    - name: Commit and Push Result
      id: git_commit
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Use the automatically provided GITHUB_TOKEN
      run: |
        git config --global user.email "you@example.com"
        git config --global user.name "Your Name"
        git add docs/scraped_table_en.csv docs/scraped_table_fr.csv docs/scraped_content_eng.html docs/scraped_content_fra.html *.atom
        git commit --allow-empty -m "Update scraped data and content"
        git push
      continue-on-error: true

    - name: Check Commit Message
      id: check_commit_message
      run: |
        COMMIT_MESSAGE=$(git log -1 --pretty=%B)
        echo "Last commit message: $COMMIT_MESSAGE"
        if [[ "$COMMIT_MESSAGE" == *"Update scraped data and content"* ]]; then
          echo "changed=true" >> $GITHUB_ENV
        else
          echo "changed=false" >> $GITHUB_ENV
        fi

    - name: Take Screenshot if Changes Detected
      if: env.changed == 'true'
      run: |
        node -e "
        const puppeteer = require('puppeteer');
        (async () => {
          const browser = await puppeteer.launch();
          const page = await browser.newPage();
          await page.goto('https://www.canada.ca/en/government/system/digital-government/digital-government-innovations/enabling-interoperability/gc-enterprise-data-reference-standards.html');
          await page.screenshot({ path: 'docs/screenshot_en.png' });
          await page.goto('https://www.canada.ca/fr/gouvernement/systeme/gouvernement-numerique/innovations-gouvernementales-numeriques/permettre-interoperabilite/normes-referentielles-pangouvernementales-relatives-donnees-gc.html');
          await page.screenshot({ path: 'docs/screenshot_fr.png' });
          await browser.close();
        })();
        "

    - name: Create Issue if Changes Detected
      if: env.changed == 'true'
      uses: peter-evans/create-issue-from-file@v4
      with:
        title: "Data Change Detected on Website"
        content-filepath: issue_body.md
        labels: update, screenshot
        assignees: your-github-username
